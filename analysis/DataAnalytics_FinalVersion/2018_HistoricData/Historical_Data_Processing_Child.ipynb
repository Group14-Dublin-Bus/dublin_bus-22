{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "117bd8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas, numpy, matplotlib, seaborn libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d661f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYOFSERVICE</th>\n",
       "      <th>TRIPID</th>\n",
       "      <th>LINEID</th>\n",
       "      <th>ROUTEID</th>\n",
       "      <th>DIRECTION</th>\n",
       "      <th>PLANNEDTIME_ARR</th>\n",
       "      <th>PLANNEDTIME_DEP</th>\n",
       "      <th>ACTUALTIME_ARR</th>\n",
       "      <th>ACTUALTIME_DEP</th>\n",
       "      <th>PLANNED_TRIPTIME(s)</th>\n",
       "      <th>ACTUAL_TRIPTIME(s)</th>\n",
       "      <th>HOUROFDAY</th>\n",
       "      <th>DAYOFWEEK</th>\n",
       "      <th>MONTHOFYEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>6253783</td>\n",
       "      <td>68</td>\n",
       "      <td>68_80</td>\n",
       "      <td>1</td>\n",
       "      <td>87245</td>\n",
       "      <td>84600</td>\n",
       "      <td>87524.0</td>\n",
       "      <td>84600.0</td>\n",
       "      <td>2645</td>\n",
       "      <td>2924</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>6262138</td>\n",
       "      <td>25B</td>\n",
       "      <td>25B_271</td>\n",
       "      <td>2</td>\n",
       "      <td>30517</td>\n",
       "      <td>26460</td>\n",
       "      <td>32752.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4057</td>\n",
       "      <td>4057</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>6254942</td>\n",
       "      <td>45A</td>\n",
       "      <td>45A_70</td>\n",
       "      <td>2</td>\n",
       "      <td>35512</td>\n",
       "      <td>32100</td>\n",
       "      <td>36329.0</td>\n",
       "      <td>32082.0</td>\n",
       "      <td>3412</td>\n",
       "      <td>4247</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>6259460</td>\n",
       "      <td>25A</td>\n",
       "      <td>25A_273</td>\n",
       "      <td>1</td>\n",
       "      <td>57261</td>\n",
       "      <td>54420</td>\n",
       "      <td>58463.0</td>\n",
       "      <td>54443.0</td>\n",
       "      <td>2841</td>\n",
       "      <td>4020</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-07</td>\n",
       "      <td>6253175</td>\n",
       "      <td>14</td>\n",
       "      <td>14_15</td>\n",
       "      <td>1</td>\n",
       "      <td>85383</td>\n",
       "      <td>81600</td>\n",
       "      <td>84682.0</td>\n",
       "      <td>81608.0</td>\n",
       "      <td>3783</td>\n",
       "      <td>3074</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182529</th>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>6765849</td>\n",
       "      <td>123</td>\n",
       "      <td>123_36</td>\n",
       "      <td>2</td>\n",
       "      <td>61560</td>\n",
       "      <td>57840</td>\n",
       "      <td>61365.0</td>\n",
       "      <td>57859.0</td>\n",
       "      <td>3720</td>\n",
       "      <td>3506</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182530</th>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>6765469</td>\n",
       "      <td>75</td>\n",
       "      <td>75_17</td>\n",
       "      <td>1</td>\n",
       "      <td>53416</td>\n",
       "      <td>48600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48823.0</td>\n",
       "      <td>4816</td>\n",
       "      <td>4816</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182531</th>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>6765486</td>\n",
       "      <td>33D</td>\n",
       "      <td>33D_62</td>\n",
       "      <td>2</td>\n",
       "      <td>29460</td>\n",
       "      <td>26400</td>\n",
       "      <td>29904.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3060</td>\n",
       "      <td>3060</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182532</th>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>6764987</td>\n",
       "      <td>70</td>\n",
       "      <td>70_60</td>\n",
       "      <td>1</td>\n",
       "      <td>65277</td>\n",
       "      <td>60600</td>\n",
       "      <td>66341.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4677</td>\n",
       "      <td>4677</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182533</th>\n",
       "      <td>2018-05-14</td>\n",
       "      <td>6765012</td>\n",
       "      <td>27</td>\n",
       "      <td>27_19</td>\n",
       "      <td>1</td>\n",
       "      <td>47722</td>\n",
       "      <td>41700</td>\n",
       "      <td>47508.0</td>\n",
       "      <td>41642.0</td>\n",
       "      <td>6022</td>\n",
       "      <td>5866</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182534 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DAYOFSERVICE   TRIPID LINEID  ROUTEID  DIRECTION  PLANNEDTIME_ARR  \\\n",
       "0         2018-02-07  6253783     68    68_80          1            87245   \n",
       "1         2018-02-07  6262138    25B  25B_271          2            30517   \n",
       "2         2018-02-07  6254942    45A   45A_70          2            35512   \n",
       "3         2018-02-07  6259460    25A  25A_273          1            57261   \n",
       "4         2018-02-07  6253175     14    14_15          1            85383   \n",
       "...              ...      ...    ...      ...        ...              ...   \n",
       "2182529   2018-05-14  6765849    123   123_36          2            61560   \n",
       "2182530   2018-05-14  6765469     75    75_17          1            53416   \n",
       "2182531   2018-05-14  6765486    33D   33D_62          2            29460   \n",
       "2182532   2018-05-14  6764987     70    70_60          1            65277   \n",
       "2182533   2018-05-14  6765012     27    27_19          1            47722   \n",
       "\n",
       "         PLANNEDTIME_DEP  ACTUALTIME_ARR  ACTUALTIME_DEP  PLANNED_TRIPTIME(s)  \\\n",
       "0                  84600         87524.0         84600.0                 2645   \n",
       "1                  26460         32752.0             NaN                 4057   \n",
       "2                  32100         36329.0         32082.0                 3412   \n",
       "3                  54420         58463.0         54443.0                 2841   \n",
       "4                  81600         84682.0         81608.0                 3783   \n",
       "...                  ...             ...             ...                  ...   \n",
       "2182529            57840         61365.0         57859.0                 3720   \n",
       "2182530            48600             NaN         48823.0                 4816   \n",
       "2182531            26400         29904.0             NaN                 3060   \n",
       "2182532            60600         66341.0             NaN                 4677   \n",
       "2182533            41700         47508.0         41642.0                 6022   \n",
       "\n",
       "         ACTUAL_TRIPTIME(s)  HOUROFDAY  DAYOFWEEK  MONTHOFYEAR  \n",
       "0                      2924       23.0          2            2  \n",
       "1                      4057        7.0          2            2  \n",
       "2                      4247        9.0          2            2  \n",
       "3                      4020       15.0          2            2  \n",
       "4                      3074       23.0          2            2  \n",
       "...                     ...        ...        ...          ...  \n",
       "2182529                3506       16.0          0            5  \n",
       "2182530                4816       14.0          0            5  \n",
       "2182531                3060        7.0          0            5  \n",
       "2182532                4677       17.0          0            5  \n",
       "2182533                5866       12.0          0            5  \n",
       "\n",
       "[2182534 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrips_copy = pd.read_csv('trips_copy.csv')\n",
    "dftrips_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf2e15e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'68'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%store -r data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5438045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the tripid where lineid is 46A\n",
    "tripid_list = dftrips_copy['TRIPID'][dftrips_copy['LINEID'] == data].tolist()\n",
    " \n",
    "# list of dataframes\n",
    "df_list = []\n",
    "\n",
    "# iterating over each chunk in the leave times cleaned csv\n",
    "chunksize = 10 ** 6\n",
    "for chunk in pd.read_csv(\"rt_leavetimes_DB_2018.txt\", sep=';', chunksize=chunksize):\n",
    "    # adding the data in the chunk if the trip id is in the list we specified earlier\n",
    "    df_list.append(chunk[chunk['TRIPID'].isin(tripid_list)])\n",
    "    \n",
    "df_concat = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae39778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the datatype of dftrips into proper type\n",
    "dftrips_copy['DAYOFSERVICE'] = dftrips_copy['DAYOFSERVICE'].astype('datetime64')\n",
    "dftrips_copy['LINEID'] = dftrips_copy['LINEID'].astype('category')\n",
    "dftrips_copy['ROUTEID'] = dftrips_copy['ROUTEID'].astype('category')\n",
    "\n",
    "#Convert the datatype into proper type\n",
    "categorical_columns = df_concat[['TRIPID','DATASOURCE','NOTE']].columns\n",
    "continuous_columns = df_concat[['PROGRNUMBER','STOPPOINTID','PLANNEDTIME_ARR','PLANNEDTIME_DEP','ACTUALTIME_ARR','ACTUALTIME_DEP','VEHICLEID','PASSENGERS','PASSENGERSIN','PASSENGERSOUT','DISTANCE','SUPPRESSED','JUSTIFICATIONID']].columns\n",
    "datetime_columns = df_concat[['DAYOFSERVICE', 'LASTUPDATE']].columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    df_concat[column] = df_concat[column].astype('category') \n",
    "    \n",
    "for column in datetime_columns:\n",
    "    df_concat[column] = df_concat[column].astype('datetime64') \n",
    "    \n",
    "    \n",
    "# Dropping unnecessary columns\n",
    "df_concat = df_concat.drop(columns=['DATASOURCE', 'VEHICLEID', 'PASSENGERS','PASSENGERSIN','PASSENGERSOUT', 'DISTANCE', 'SUPPRESSED', 'LASTUPDATE', 'NOTE', 'JUSTIFICATIONID'])\n",
    "\n",
    "#Merge with the dftrips_copy dataset\n",
    "df_concat=df_concat.merge(dftrips_copy, on = ['DAYOFSERVICE', 'TRIPID'])\n",
    "\n",
    "#fill in the null values in ACTUALTIME_DEP_y\n",
    "for i in range(len(df_concat)):\n",
    "    if (np.isnan(df_concat[\"ACTUALTIME_DEP_y\"][i])):\n",
    "        df_concat[\"ACTUALTIME_DEP_y\"][i] = df_concat[\"PLANNEDTIME_DEP_y\"][i]\n",
    "        \n",
    "#Calculate the accumulated travel time\n",
    "df_concat['ACC_TRAVELTIME(s)'] = (df_concat['ACTUALTIME_ARR_x'] - df_concat['ACTUALTIME_DEP_y'])\n",
    "\n",
    "#ONLY keep the columnd we need\n",
    "df_concat = df_concat[['DAYOFSERVICE','TRIPID','PROGRNUMBER','STOPPOINTID','LINEID','DIRECTION','PLANNED_TRIPTIME(s)','ACTUAL_TRIPTIME(s)','HOUROFDAY','DAYOFWEEK','MONTHOFYEAR','ACC_TRAVELTIME(s)']]\n",
    "\n",
    "#Adding the information of 'HOUROFDAY' to the 'DAYOFSERVICE' column\n",
    "for i in range(len(df_concat['DAYOFSERVICE'])):\n",
    "    df_concat['DAYOFSERVICE'][i] = df_concat['DAYOFSERVICE'][i] + pd.Timedelta(hours=df_concat['HOUROFDAY'][i])\n",
    "    \n",
    "#Importing the weather data\n",
    "dfweather = pd.read_csv('weather2018_clean.csv')\n",
    "\n",
    "#Convert data type of dfweather\n",
    "dfweather['DAYOFSERVICE'] = dfweather['DAYOFSERVICE'].astype('datetime64')\n",
    "dfweather['weather_main'] = dfweather['weather_main'].astype('category')\n",
    "dfweather['weather_description'] = dfweather['weather_description'].astype('category')\n",
    "\n",
    "# merging data with weather data (merge on date and hour)\n",
    "df_concat = df_concat.merge(dfweather, on=['DAYOFSERVICE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the blank with 0.\n",
    "#df_concat['visibility'].fillna(0, inplace=True)\n",
    "#df_concat['wind_gust'].fillna(0, inplace=True)\n",
    "#df_concat['rain_1h'].fillna(0, inplace=True)\n",
    "#df_concat['snow_1h'].fillna(0, inplace=True)\n",
    "\n",
    "# list trip and dayofservice for all trips with outlier data (4 times above mean travel time or below 0 travel time)\n",
    "outliers = df_concat.loc[(df_concat['ACC_TRAVELTIME(s)'] > df_concat['ACC_TRAVELTIME(s)'].mean()*4) | (df_concat['ACC_TRAVELTIME(s)'] < 0)].index\n",
    "#drop the outliers\n",
    "df_concat = df_concat.drop(outliers)\n",
    "\n",
    "# route 46A trips which took over 10 mins to reach second stop\n",
    "dfr1longstart = df_concat.loc[(df_concat['ACC_TRAVELTIME(s)'] > 600) & (df_concat['PROGRNUMBER'] == 2)].loc[(df_concat['ACC_TRAVELTIME(s)'] > 600) & (df_concat['PROGRNUMBER'] == 2)]\n",
    "# index list for rows with over 600 travel time by stop 2\n",
    "longStartIndexList = df_concat.loc[(df_concat['DAYOFSERVICE'].isin(dfr1longstart['DAYOFSERVICE'].unique())) & (df_concat['TRIPID'].isin(dfr1longstart['TRIPID'].unique()))].index.tolist()\n",
    "# dropping trips which had over 600 travel time by stop 2\n",
    "df_concat = df_concat.drop(longStartIndexList)\n",
    "\n",
    "#Select the features we need for modeling and Copy the original version of dataset\n",
    "df_concat_ver1 = df_concat[['DIRECTION','PROGRNUMBER','PLANNED_TRIPTIME(s)','HOUROFDAY','DAYOFWEEK','MONTHOFYEAR','ACC_TRAVELTIME(s)','temp','wind_speed','rain_1h']]\n",
    "\n",
    "\n",
    "# # set up dummies features\n",
    "# df_concat_ver1 = pd.get_dummies(df_concat_ver1, drop_first=True)\n",
    "# df_concat_ver1.dtypes\n",
    "\n",
    "#Setting up the train/test split\n",
    "# y is the target\n",
    "y = df_concat_ver1[\"ACC_TRAVELTIME(s)\"]\n",
    "# X is everything else\n",
    "X = df_concat_ver1.drop([\"ACC_TRAVELTIME(s)\"],1)\n",
    "# Split the dataset into two datasets: 70% training and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1,  test_size=0.3)\n",
    "\n",
    "#Record the time of setting up linear regression model\n",
    "start_time1 = time.time()\n",
    "# Train aka fit, a model using all continuous and categorical features.\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "#Predict the test dataset\n",
    "linreg_predictions_test = linreg.predict(X_test)\n",
    "    \n",
    "#Calculate the metrics\n",
    "MAE_linreg = metrics.mean_absolute_error(y_test, linreg_predictions_test)\n",
    "RMSE_linreg = metrics.mean_squared_error(y_test, linreg_predictions_test)**0.5\n",
    "R2_linreg = metrics.r2_score(y_test, linreg_predictions_test)\n",
    "    \n",
    "end_time1 = time.time()\n",
    "timer1 = end_time1 - start_time1\n",
    "    \n",
    "# writing these evaluation scores to a file\n",
    "f = open(\"LinearRegres_Evaluation_06_08.txt\", \"a\")\n",
    "f.write(\"\\nCombination of features\" + str(i) + \".\\n\")\n",
    "f.write(\"\\nLine: \" + str(data) + \". MAE: \" + str(MAE_linreg) + \". RMSE: \" + str(RMSE_linreg) + \". R2 Score: \" + str(R2_linreg) + \".\\n\")\n",
    "f.write(\"\\nModel running time: \" + str(timer1) + \".\\n\")\n",
    "f.close()\n",
    "    \n",
    "#Record the time of setting up random forest model\n",
    "start_time2 = time.time()\n",
    "    \n",
    "# Train RF with 10 trees\n",
    "rfc = RandomForestRegressor(n_estimators=10, max_features='auto', oob_score=True, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "#Predict the test dataset\n",
    "rfc_predictions_test = rfc.predict(X_test)\n",
    "\n",
    "#Evaluation scores\n",
    "MAE_rfc = metrics.mean_absolute_error(y_test, rfc_predictions_test)\n",
    "RMSE_rfc = metrics.mean_squared_error(y_test, rfc_predictions_test)**0.5\n",
    "R2_rfc = metrics.r2_score(y_test, rfc_predictions_test)\n",
    "    \n",
    "end_time2 = time.time()\n",
    "timer2 = end_time2 - start_time2\n",
    "    \n",
    "# writing these evaluation scores to a file\n",
    "f = open(\"RandomForest_Evaluation_06_08.txt\", \"a\")\n",
    "f.write(\"\\nCombination of features\" + str(i) + \".\\n\")\n",
    "f.write(\"\\nLine: \" + str(data) + \". MAE: \" + str(MAE_rfc) + \". RMSE: \" + str(RMSE_rfc) + \". R2 Score: \" + str(R2_rfc) + \".\\n\")\n",
    "f.write(\"\\nModel running time: \" + str(timer2) + \".\\n\")\n",
    "f.close()\n",
    "\n",
    "# save the model to pickle file\n",
    "filename = \"ModelResult_LinearRegression/PickleFiles_{}.pkl\".format(lineid)\n",
    "pickle.dump(linreg, open(filename, 'wb'))\n",
    "\n",
    "# save the model to pickle file\n",
    "filename = \"ModelResult_RandomForest/PickleFiles_{}.pkl\".format(lineid)\n",
    "pickle.dump(rfc, open(filename, 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
